{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GBIF Silver → Gold: dimension tables\n",
        "\n",
        "Reads GBIF occurrences from **silver** and creates two **gold** dimension tables:\n",
        "\n",
        "| Table | S3 path | Description |\n",
        "|-------|---------|-------------|\n",
        "| **gbif_species_dim** | `s3://ie-datalake/gold/gbif_species_dim/country=XX/year=YYYY/` | One row per species per (country, year): taxon_key, occurrence_count, is_threatened, is_invasive |\n",
        "| **gbif_species_h3_mapping** | `s3://ie-datalake/gold/gbif_species_h3_mapping/country=XX/year=YYYY/h3_resolution=N/` | Mapping: which species are in which H3 cell – for fast region lookups |\n",
        "\n",
        "## gbif_species_dim\n",
        "- **Partition:** country, year\n",
        "- **Columns:** taxon_key, species_name, occurrence_count, is_threatened, is_invasive\n",
        "- **Purpose:** Species-level summary per country/year (1k occurrences → 1 row)\n",
        "\n",
        "## gbif_species_h3_mapping\n",
        "- **Partition:** country, year, h3_resolution\n",
        "- **Columns:** h3_index, taxon_key, occurrence_count, is_threatened, is_invasive\n",
        "- **Purpose:** Quick lookup: \"which species are in this region (H3 cell)?\"\n",
        "\n",
        "## Memory strategy\n",
        "- Column projection (only needed columns from silver)\n",
        "- PyArrow native S3 for reads (5–10× faster than s3fs)\n",
        "- One (country, year) partition in RAM at a time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# CONFIGURATION\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "COUNTRIES: list[str] = [\"ES\"]\n",
        "YEAR_START: int = 2024\n",
        "YEAR_END:   int = 2024\n",
        "\n",
        "H3_RESOLUTIONS: list[int] = [9, 8, 7, 6]\n",
        "\n",
        "S3_BUCKET:     str = \"ie-datalake\"\n",
        "SILVER_PREFIX: str = \"silver/gbif\"\n",
        "GOLD_SPECIES_DIM:     str = \"gold/gbif_species_dim\"\n",
        "GOLD_H3_MAPPING:      str = \"gold/gbif_species_h3_mapping\"\n",
        "AWS_PROFILE:   str = \"486717354268_PowerUserAccess\"\n",
        "\n",
        "PARQUET_COMPRESSION: str = \"snappy\"\n",
        "THREATENED_CATS: list[str] = [\"CR\", \"EN\", \"VU\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q pyarrow s3fs pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22:25:27 [INFO] Found credentials in shared credentials file: ~/.aws/credentials\n",
            "22:25:27 [INFO] S3 ready (profile=486717354268_PowerUserAccess, region=eu-west-2)\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "from typing import Optional\n",
        "\n",
        "import boto3\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pyarrow.fs as pafs\n",
        "import pyarrow.parquet as pq\n",
        "import s3fs\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    datefmt=\"%H:%M:%S\",\n",
        "    force=True,\n",
        ")\n",
        "log = logging.getLogger(\"gbif_dim\")\n",
        "\n",
        "# s3fs for writes\n",
        "fs = s3fs.S3FileSystem(profile=AWS_PROFILE)\n",
        "\n",
        "# PyArrow native S3 for reads (faster)\n",
        "_boto = boto3.Session(profile_name=AWS_PROFILE)\n",
        "_creds = _boto.get_credentials().get_frozen_credentials()\n",
        "_region = \"eu-west-2\"\n",
        "fs_read = pafs.S3FileSystem(\n",
        "    access_key=_creds.access_key,\n",
        "    secret_key=_creds.secret_key,\n",
        "    session_token=_creds.token,\n",
        "    region=_region,\n",
        ")\n",
        "\n",
        "pa.set_io_thread_count(min(16, (os.cpu_count() or 4) * 2))\n",
        "pa.set_cpu_count(os.cpu_count() or 4)\n",
        "\n",
        "log.info(\"S3 ready (profile=%s, region=%s)\", AWS_PROFILE, _region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ─── Column helpers (case-insensitive, schema varies) ─────────────────────────\n",
        "\n",
        "def _find_col(df: pd.DataFrame, *candidates: str) -> Optional[str]:\n",
        "    for c in candidates:\n",
        "        norm = c.lower().replace(\"_\", \"\")\n",
        "        for col in df.columns:\n",
        "            if col.lower().replace(\"_\", \"\") == norm:\n",
        "                return col\n",
        "    return None\n",
        "\n",
        "\n",
        "# ─── Read silver with projection ─────────────────────────────────────────────\n",
        "\n",
        "_COLS = [\n",
        "    \"taxonKey\", \"speciesKey\", \"species\", \"scientificName\",\n",
        "    \"h3_9\", \"h3_8\", \"h3_7\", \"h3_6\",\n",
        "    \"iucn_cat\", \"iucnRedListCategory\",\n",
        "    \"is_invasive_any\",\n",
        "]\n",
        "\n",
        "\n",
        "def read_silver(country: str, year: int) -> pd.DataFrame:\n",
        "    native_path = f\"{S3_BUCKET}/{SILVER_PREFIX}/country={country}/year={year}\"\n",
        "    log_path = f\"s3://{native_path}\"\n",
        "\n",
        "    info = fs_read.get_file_info(native_path)\n",
        "    if info.type == pafs.FileType.NotFound:\n",
        "        raise FileNotFoundError(f\"Silver partition not found: {log_path}\")\n",
        "\n",
        "    log.info(\"Reading silver: %s\", log_path)\n",
        "    t0 = time.time()\n",
        "\n",
        "    dataset = ds.dataset(native_path, filesystem=fs_read, format=\"parquet\")\n",
        "    available = {c.lower().replace(\"_\", \"\"): c for c in dataset.schema.names}\n",
        "    project = []\n",
        "    for want in _COLS:\n",
        "        key = want.lower().replace(\"_\", \"\")\n",
        "        if key in available:\n",
        "            project.append(available[key])\n",
        "\n",
        "    log.info(\"Projecting %d / %d columns\", len(project), len(dataset.schema.names))\n",
        "    table = dataset.scanner(columns=project, use_threads=True).to_table()\n",
        "    df = table.to_pandas()\n",
        "\n",
        "    log.info(\"Loaded %d rows in %.1fs\", len(df), time.time() - t0)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "84a07039",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ─── Build species_dim (one row per taxon_key per country/year) ──────────────\n",
        "\n",
        "def build_species_dim(df: pd.DataFrame, country: str, year: int) -> pd.DataFrame:\n",
        "    tk_col = _find_col(df, \"taxonKey\", \"speciesKey\")\n",
        "    if not tk_col:\n",
        "        raise ValueError(\"No taxonKey/speciesKey column found\")\n",
        "\n",
        "    iucn_col = _find_col(df, \"iucn_cat\", \"iucnRedListCategory\")\n",
        "    inv_col = _find_col(df, \"is_invasive_any\")\n",
        "    name_col = _find_col(df, \"species\", \"scientificName\")\n",
        "\n",
        "    df = df[df[tk_col].notna()].copy()\n",
        "    df[\"_iucn_norm\"] = df[iucn_col].astype(str).str.upper().str.strip() if iucn_col else \"\"\n",
        "    df[\"_threatened\"] = df[\"_iucn_norm\"].isin(THREATENED_CATS)\n",
        "    df[\"_invasive\"] = df[inv_col].fillna(False).astype(bool) if inv_col else False\n",
        "\n",
        "    g = df.groupby(tk_col)\n",
        "    agg = g.agg(\n",
        "        occurrence_count=(tk_col, \"count\"),\n",
        "        is_threatened=(\"_threatened\", \"any\"),\n",
        "        is_invasive=(\"_invasive\", \"any\"),\n",
        "    ).reset_index()\n",
        "\n",
        "    if name_col:\n",
        "        first_name = df.groupby(tk_col)[name_col].first().reset_index()\n",
        "        agg = agg.merge(first_name, on=tk_col, how=\"left\")\n",
        "        agg = agg.rename(columns={name_col: \"species_name\", tk_col: \"taxon_key\"})\n",
        "    else:\n",
        "        agg = agg.rename(columns={tk_col: \"taxon_key\"})\n",
        "        agg[\"species_name\"] = None\n",
        "\n",
        "    agg[\"country\"] = country\n",
        "    agg[\"year\"] = int(year)\n",
        "    agg[\"is_threatened\"] = agg[\"is_threatened\"].astype(bool)\n",
        "    agg[\"is_invasive\"] = agg[\"is_invasive\"].astype(bool)\n",
        "\n",
        "    return agg[[\"taxon_key\", \"species_name\", \"occurrence_count\", \"is_threatened\", \"is_invasive\", \"country\", \"year\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c6e220f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ─── Build h3_mapping (one row per h3_index × taxon_key per resolution) ──────\n",
        "\n",
        "def build_h3_mapping(\n",
        "    df: pd.DataFrame,\n",
        "    country: str,\n",
        "    year: int,\n",
        "    h3_resolution: int,\n",
        ") -> pd.DataFrame:\n",
        "    h3_col = f\"h3_{h3_resolution}\"\n",
        "    if h3_col not in df.columns:\n",
        "        raise ValueError(f\"Column {h3_col} not found\")\n",
        "\n",
        "    tk_col = _find_col(df, \"taxonKey\", \"speciesKey\")\n",
        "    if not tk_col:\n",
        "        raise ValueError(\"No taxonKey/speciesKey column found\")\n",
        "\n",
        "    iucn_col = _find_col(df, \"iucn_cat\", \"iucnRedListCategory\")\n",
        "    inv_col = _find_col(df, \"is_invasive_any\")\n",
        "\n",
        "    sub = df[[h3_col, tk_col]].dropna()\n",
        "    sub[\"_iucn_norm\"] = df.loc[sub.index, iucn_col].astype(str).str.upper().str.strip() if iucn_col else \"\"\n",
        "    sub[\"_threatened\"] = sub[\"_iucn_norm\"].isin(THREATENED_CATS)\n",
        "    sub[\"_invasive\"] = df.loc[sub.index, inv_col].fillna(False).astype(bool) if inv_col else False\n",
        "\n",
        "    g = sub.groupby([h3_col, tk_col])\n",
        "    agg = g.agg(\n",
        "        occurrence_count=(tk_col, \"count\"),\n",
        "        is_threatened=(\"_threatened\", \"any\"),\n",
        "        is_invasive=(\"_invasive\", \"any\"),\n",
        "    ).reset_index()\n",
        "\n",
        "    agg = agg.rename(columns={h3_col: \"h3_index\", tk_col: \"taxon_key\"})\n",
        "    agg[\"h3_resolution\"] = h3_resolution\n",
        "    agg[\"country\"] = country\n",
        "    agg[\"year\"] = int(year)\n",
        "    agg[\"is_threatened\"] = agg[\"is_threatened\"].astype(bool)\n",
        "    agg[\"is_invasive\"] = agg[\"is_invasive\"].astype(bool)\n",
        "\n",
        "    return agg[[\"h3_index\", \"taxon_key\", \"occurrence_count\", \"is_threatened\", \"is_invasive\", \"h3_resolution\", \"country\", \"year\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22:25:42 [INFO] Processing 1 partition(s): [('ES', 2024)]\n",
            "22:25:42 [INFO] \n",
            "── ES / 2024 ──────────────────────────────────────────────────\n",
            "22:25:42 [INFO] Reading silver: s3://ie-datalake/silver/gbif/country=ES/year=2024\n",
            "22:25:45 [INFO] Projecting 10 / 64 columns\n",
            "22:26:49 [INFO] Loaded 7421317 rows in 67.5s\n",
            "22:26:55 [INFO] Found credentials in shared credentials file: ~/.aws/credentials\n",
            "22:26:56 [INFO]   species_dim: 23281 species → s3://ie-datalake/gold/gbif_species_dim/country=ES/year=2024/ (6.7s)\n",
            "22:27:04 [INFO]   h3_mapping res=9: 2069923 rows → s3://ie-datalake/gold/gbif_species_h3_mapping/country=ES/year=2024/h3_resolution=9/ (7.1s)\n",
            "22:27:09 [INFO]   h3_mapping res=8: 1833669 rows → s3://ie-datalake/gold/gbif_species_h3_mapping/country=ES/year=2024/h3_resolution=8/ (5.8s)\n",
            "22:27:15 [INFO]   h3_mapping res=7: 1467200 rows → s3://ie-datalake/gold/gbif_species_h3_mapping/country=ES/year=2024/h3_resolution=7/ (5.4s)\n",
            "22:27:20 [INFO]   h3_mapping res=6: 1001791 rows → s3://ie-datalake/gold/gbif_species_h3_mapping/country=ES/year=2024/h3_resolution=6/ (4.8s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "════════════════════════════════════════════════════════════\n",
            "Done: 1 species_dim, 4 h3_mapping writes\n",
            "════════════════════════════════════════════════════════════\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>year</th>\n",
              "      <th>n_species</th>\n",
              "      <th>s3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "      <td>23281</td>\n",
              "      <td>s3://ie-datalake/gold/gbif_species_dim/country...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  country  year  n_species                                                 s3\n",
              "0      ES  2024      23281  s3://ie-datalake/gold/gbif_species_dim/country..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>year</th>\n",
              "      <th>h3_resolution</th>\n",
              "      <th>n_rows</th>\n",
              "      <th>s3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "      <td>9</td>\n",
              "      <td>2069923</td>\n",
              "      <td>s3://ie-datalake/gold/gbif_species_h3_mapping/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "      <td>8</td>\n",
              "      <td>1833669</td>\n",
              "      <td>s3://ie-datalake/gold/gbif_species_h3_mapping/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "      <td>7</td>\n",
              "      <td>1467200</td>\n",
              "      <td>s3://ie-datalake/gold/gbif_species_h3_mapping/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "      <td>6</td>\n",
              "      <td>1001791</td>\n",
              "      <td>s3://ie-datalake/gold/gbif_species_h3_mapping/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  country  year  h3_resolution   n_rows  \\\n",
              "0      ES  2024              9  2069923   \n",
              "1      ES  2024              8  1833669   \n",
              "2      ES  2024              7  1467200   \n",
              "3      ES  2024              6  1001791   \n",
              "\n",
              "                                                  s3  \n",
              "0  s3://ie-datalake/gold/gbif_species_h3_mapping/...  \n",
              "1  s3://ie-datalake/gold/gbif_species_h3_mapping/...  \n",
              "2  s3://ie-datalake/gold/gbif_species_h3_mapping/...  \n",
              "3  s3://ie-datalake/gold/gbif_species_h3_mapping/...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ─── Main pipeline ───────────────────────────────────────────────────────────\n",
        "\n",
        "years = list(range(YEAR_END, YEAR_START - 1, -1))\n",
        "partition_plan = [(c, y) for c in COUNTRIES for y in years]\n",
        "\n",
        "log.info(\"Processing %d partition(s): %s\", len(partition_plan), partition_plan)\n",
        "\n",
        "completed_dim: list[dict] = []\n",
        "completed_h3: list[dict] = []\n",
        "errors: list[dict] = []\n",
        "\n",
        "for country, year in partition_plan:\n",
        "    log.info(\"\\n── %s / %s ──────────────────────────────────────────────────\", country, year)\n",
        "\n",
        "    try:\n",
        "        df = read_silver(country, year)\n",
        "    except FileNotFoundError as e:\n",
        "        log.error(\"%s\", e)\n",
        "        errors.append({\"country\": country, \"year\": year, \"error\": str(e)})\n",
        "        continue\n",
        "\n",
        "    # 1. gbif_species_dim\n",
        "    t0 = time.time()\n",
        "    dim = build_species_dim(df, country, year)\n",
        "    s3_dim = f\"{S3_BUCKET}/{GOLD_SPECIES_DIM}/country={country}/year={year}\"\n",
        "    table_dim = pa.Table.from_pandas(dim, preserve_index=False)\n",
        "    pq.write_to_dataset(\n",
        "        table_dim,\n",
        "        root_path=f\"s3://{s3_dim}\",\n",
        "        filesystem=fs,\n",
        "        compression=PARQUET_COMPRESSION,\n",
        "        existing_data_behavior=\"delete_matching\",\n",
        "    )\n",
        "    log.info(\"  species_dim: %d species → s3://%s/ (%.1fs)\", len(dim), s3_dim, time.time() - t0)\n",
        "    completed_dim.append({\"country\": country, \"year\": year, \"n_species\": len(dim), \"s3\": f\"s3://{s3_dim}/\"})\n",
        "\n",
        "    # 2. gbif_species_h3_mapping (per resolution)\n",
        "    for res in H3_RESOLUTIONS:\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            h3_df = build_h3_mapping(df, country, year, res)\n",
        "            s3_h3 = f\"{S3_BUCKET}/{GOLD_H3_MAPPING}/country={country}/year={year}/h3_resolution={res}\"\n",
        "            table_h3 = pa.Table.from_pandas(h3_df, preserve_index=False)\n",
        "            pq.write_to_dataset(\n",
        "                table_h3,\n",
        "                root_path=f\"s3://{s3_h3}\",\n",
        "                filesystem=fs,\n",
        "                compression=PARQUET_COMPRESSION,\n",
        "                existing_data_behavior=\"delete_matching\",\n",
        "            )\n",
        "            log.info(\"  h3_mapping res=%d: %d rows → s3://%s/ (%.1fs)\", res, len(h3_df), s3_h3, time.time() - t0)\n",
        "            completed_h3.append({\"country\": country, \"year\": year, \"h3_resolution\": res, \"n_rows\": len(h3_df), \"s3\": f\"s3://{s3_h3}/\"})\n",
        "        except Exception as e:\n",
        "            log.error(\"  h3_mapping res=%d failed: %s\", res, e)\n",
        "            errors.append({\"country\": country, \"year\": year, \"h3_resolution\": res, \"error\": str(e)})\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"═\" * 60)\n",
        "print(f\"Done: {len(completed_dim)} species_dim, {len(completed_h3)} h3_mapping writes\")\n",
        "if errors:\n",
        "    print(f\"Errors: {len(errors)}\")\n",
        "print(\"═\" * 60)\n",
        "\n",
        "if completed_dim:\n",
        "    display(pd.DataFrame(completed_dim))\n",
        "if completed_h3:\n",
        "    display(pd.DataFrame(completed_h3))\n",
        "if errors:\n",
        "    display(pd.DataFrame(errors))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

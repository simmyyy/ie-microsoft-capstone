{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GBIF Silver → Gold: `gbif_cell_metrics`\n",
        "\n",
        "Reads H3-indexed occurrences from the **silver** layer and aggregates them into\n",
        "a **gold** metrics table partitioned by `country / year / h3_resolution`.\n",
        "\n",
        "| Layer | S3 path |\n",
        "|-------|---------|\n",
        "| Silver in | `s3://ie-datalake/silver/gbif/country=XX/year=YYYY/` |\n",
        "| Gold out  | `s3://ie-datalake/gold/gbif_cell_metrics/country=XX/year=YYYY/h3_resolution=N/` |\n",
        "\n",
        "## Metrics per `(country, year, h3_resolution, h3_index)`\n",
        "\n",
        "### Observation\n",
        "| Column | Description |\n",
        "|--------|-------------|\n",
        "| `observation_count` | Total occurrence records |\n",
        "| `species_richness_cell` | Distinct species (speciesKey → taxonKey → species string) |\n",
        "| `unique_datasets` | Distinct datasetKey |\n",
        "| `avg_coordinate_uncertainty_m` | Mean coordinateUncertaintyInMeters |\n",
        "| `pct_uncertainty_gt_10km` | Share of records with uncertainty > 10 000 m |\n",
        "\n",
        "### IUCN / Threat\n",
        "| Column | Description |\n",
        "|--------|-------------|\n",
        "| `n_assessed_species` | Distinct species with any IUCN category |\n",
        "| `n_sp_cr / en / vu / nt / lc / dd / ne` | Distinct species per category (only if present) |\n",
        "| `n_threatened_species` | Distinct CR + EN + VU species |\n",
        "| `threat_score_weighted` | Σ weight(iucn) per **distinct** species; CR=5, EN=4, VU=3, NT=2 |\n",
        "\n",
        "### Diversity\n",
        "| Column | Description |\n",
        "|--------|-------------|\n",
        "| `shannon_H` | Shannon-Wiener entropy (numerically stable) |\n",
        "| `simpson_1_minus_D` | Simpson diversity index 1 − D |\n",
        "\n",
        "### Data Quality Index (0–1)\n",
        "| Column | Description |\n",
        "|--------|-------------|\n",
        "| `dqi` | Composite: coord completeness, species-id completeness, uncertainty quality, iucn coverage |\n",
        "\n",
        "## Memory strategy\n",
        "- Only **required columns** are loaded (pyarrow projection pushdown).\n",
        "- One `(country, year)` partition is held in RAM at a time.\n",
        "- Diversity metrics are computed on the **species-count table** (groupby result),\n",
        "  not on the full record-level DataFrame.\n",
        "\n",
        "## Requirements\n",
        "```\n",
        "pip install pyarrow s3fs pandas numpy\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# CONFIGURATION\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "COUNTRIES: list[str] = [\"ES\"]\n",
        "YEAR_START: int = 2024\n",
        "YEAR_END:   int = 2024\n",
        "\n",
        "# H3 resolutions to aggregate (must already be present in silver)\n",
        "H3_RESOLUTIONS: list[int] = [9, 8, 7, 6]\n",
        "\n",
        "S3_BUCKET:     str = \"ie-datalake\"\n",
        "SILVER_PREFIX: str = \"silver/gbif\"\n",
        "GOLD_PREFIX:   str = \"gold/gbif_cell_metrics\"\n",
        "AWS_PROFILE:   str = \"486717354268_PowerUserAccess\"\n",
        "\n",
        "PARQUET_COMPRESSION:    str = \"snappy\"\n",
        "PARQUET_ROW_GROUP_SIZE: int = 250_000\n",
        "\n",
        "# IUCN categories to pivot (only columns with ≥1 species will be written)\n",
        "IUCN_ALL_CATS: list[str] = [\"CR\", \"EN\", \"VU\", \"NT\", \"LC\", \"DD\", \"NE\"]\n",
        "IUCN_WEIGHTS:  dict[str, int] = {\"CR\": 5, \"EN\": 4, \"VU\": 3, \"NT\": 2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16:38:05 [INFO] Found credentials in shared credentials file: ~/.aws/credentials\n",
            "16:38:05 [INFO] S3 ready (profile=486717354268_PowerUserAccess, region=eu-west-2, io_threads=16)\n",
            "16:38:05 [INFO] Gold pipeline: 1 (country×year) partitions × 4 resolutions = 4 total writes\n",
            "16:38:05 [INFO] \n",
            "── ES / 2024 ──────────────────────────────────────────────────\n",
            "16:38:05 [INFO] Reading silver: s3://ie-datalake/silver/gbif/country=ES/year=2024\n",
            "16:38:11 [INFO] Projecting 14 / 64 columns – starting download…\n",
            "16:39:37 [INFO] Loaded 7421317 rows, 14 columns in 91.2s (1976 MB RAM)\n",
            "16:39:37 [INFO] Read done in 91.9s\n",
            "16:39:37 [INFO]   res=9 | rows=7421317 | sk=specieskey | unc=coordinateuncertaintyinmeters | iucn=iucn_cat\n",
            "16:39:43 [INFO] Writing 272584 cells to s3://ie-datalake/gold/gbif_cell_metrics/country=ES/year=2024/h3_resolution=9 …\n",
            "16:39:44 [INFO] Written: s3://ie-datalake/gold/gbif_cell_metrics/country=ES/year=2024/h3_resolution=9\n",
            "16:39:44 [INFO] ✓ res=9 | 272584 cells | 7.4s\n",
            "16:39:44 [INFO]   res=8 | rows=7421317 | sk=specieskey | unc=coordinateuncertaintyinmeters | iucn=iucn_cat\n",
            "16:39:49 [INFO] Writing 149508 cells to s3://ie-datalake/gold/gbif_cell_metrics/country=ES/year=2024/h3_resolution=8 …\n",
            "16:39:50 [INFO] Written: s3://ie-datalake/gold/gbif_cell_metrics/country=ES/year=2024/h3_resolution=8\n",
            "16:39:50 [INFO] ✓ res=8 | 149508 cells | 5.4s\n",
            "16:39:50 [INFO]   res=7 | rows=7421317 | sk=specieskey | unc=coordinateuncertaintyinmeters | iucn=iucn_cat\n",
            "16:39:54 [INFO] Writing 59951 cells to s3://ie-datalake/gold/gbif_cell_metrics/country=ES/year=2024/h3_resolution=7 …\n",
            "16:39:54 [INFO] Written: s3://ie-datalake/gold/gbif_cell_metrics/country=ES/year=2024/h3_resolution=7\n",
            "16:39:54 [INFO] ✓ res=7 | 59951 cells | 4.4s\n",
            "16:39:54 [INFO]   res=6 | rows=7421317 | sk=specieskey | unc=coordinateuncertaintyinmeters | iucn=iucn_cat\n",
            "16:39:58 [INFO] Writing 15029 cells to s3://ie-datalake/gold/gbif_cell_metrics/country=ES/year=2024/h3_resolution=6 …\n",
            "16:39:58 [INFO] Written: s3://ie-datalake/gold/gbif_cell_metrics/country=ES/year=2024/h3_resolution=6\n",
            "16:39:58 [INFO] ✓ res=6 | 15029 cells | 3.9s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "════════════════════════════════════════════════════════════\n",
            "Gold pipeline complete: 4 succeeded, 0 failed\n",
            "════════════════════════════════════════════════════════════\n",
            "\n",
            "Completed:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>year</th>\n",
              "      <th>h3_resolution</th>\n",
              "      <th>n_cells</th>\n",
              "      <th>s3_uri</th>\n",
              "      <th>elapsed_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "      <td>9</td>\n",
              "      <td>272584</td>\n",
              "      <td>s3://ie-datalake/gold/gbif_cell_metrics/countr...</td>\n",
              "      <td>7.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "      <td>8</td>\n",
              "      <td>149508</td>\n",
              "      <td>s3://ie-datalake/gold/gbif_cell_metrics/countr...</td>\n",
              "      <td>5.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "      <td>7</td>\n",
              "      <td>59951</td>\n",
              "      <td>s3://ie-datalake/gold/gbif_cell_metrics/countr...</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "      <td>6</td>\n",
              "      <td>15029</td>\n",
              "      <td>s3://ie-datalake/gold/gbif_cell_metrics/countr...</td>\n",
              "      <td>3.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  country  year  h3_resolution  n_cells  \\\n",
              "0      ES  2024              9   272584   \n",
              "1      ES  2024              8   149508   \n",
              "2      ES  2024              7    59951   \n",
              "3      ES  2024              6    15029   \n",
              "\n",
              "                                              s3_uri  elapsed_s  \n",
              "0  s3://ie-datalake/gold/gbif_cell_metrics/countr...        7.4  \n",
              "1  s3://ie-datalake/gold/gbif_cell_metrics/countr...        5.4  \n",
              "2  s3://ie-datalake/gold/gbif_cell_metrics/countr...        4.4  \n",
              "3  s3://ie-datalake/gold/gbif_cell_metrics/countr...        3.9  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# SILVER → GOLD PIPELINE\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "from typing import Optional\n",
        "\n",
        "import boto3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pyarrow.fs as pafs\n",
        "import pyarrow.parquet as pq\n",
        "import s3fs\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    datefmt=\"%H:%M:%S\",\n",
        "    force=True,\n",
        ")\n",
        "log = logging.getLogger(\"gbif_gold\")\n",
        "\n",
        "# s3fs – used only for writes (pq.write_to_dataset)\n",
        "fs = s3fs.S3FileSystem(profile=AWS_PROFILE)\n",
        "\n",
        "# PyArrow native S3FileSystem – used for reads.\n",
        "# The C++ S3 client pre-fetches row-groups in parallel and uses connection\n",
        "# pooling, making it 5-10× faster than s3fs for reading Parquet files.\n",
        "_boto_session = boto3.Session(profile_name=AWS_PROFILE)\n",
        "_creds = _boto_session.get_credentials().get_frozen_credentials()\n",
        "# _region = _boto_session.region_name or \"eu-west-2\"\n",
        "_region = \"eu-west-2\"\n",
        "fs_read = pafs.S3FileSystem(\n",
        "    access_key=_creds.access_key,\n",
        "    secret_key=_creds.secret_key,\n",
        "    session_token=_creds.token,\n",
        "    region=_region,\n",
        ")\n",
        "\n",
        "# Maximise I/O and CPU parallelism for Arrow operations\n",
        "pa.set_io_thread_count(min(16, (os.cpu_count() or 4) * 2))\n",
        "pa.set_cpu_count(os.cpu_count() or 4)\n",
        "\n",
        "log.info(\n",
        "    \"S3 ready (profile=%s, region=%s, io_threads=%d)\",\n",
        "    AWS_PROFILE, _region, pa.io_thread_count(),\n",
        ")\n",
        "\n",
        "\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# UTILITIES\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def _find_col(df: pd.DataFrame, name: str) -> Optional[str]:\n",
        "    \"\"\"Case-insensitive column lookup, normalising underscores.\"\"\"\n",
        "    norm = name.lower().replace(\"_\", \"\")\n",
        "    for col in df.columns:\n",
        "        if col.lower().replace(\"_\", \"\") == norm:\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "\n",
        "def _resolve_species_col(df: pd.DataFrame) -> Optional[str]:\n",
        "    \"\"\"Return the best available species-identifier column.\"\"\"\n",
        "    for candidate in (\"speciesKey\", \"taxonKey\", \"species\", \"scientificName\"):\n",
        "        col = _find_col(df, candidate)\n",
        "        if col:\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "\n",
        "def _resolve_iucn_col(df: pd.DataFrame) -> Optional[str]:\n",
        "    \"\"\"Return the IUCN category column (from bronze enrichment or raw GBIF).\"\"\"\n",
        "    for candidate in (\"iucn_cat\", \"iucnRedListCategory\"):\n",
        "        col = _find_col(df, candidate)\n",
        "        if col and df[col].notna().any():\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# 1. READ INPUT (with column projection)\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "# Columns we want to read from silver (subset – much smaller than full schema)\n",
        "_CANDIDATE_COLS: list[str] = [\n",
        "    # H3 spatial index\n",
        "    \"h3_9\", \"h3_8\", \"h3_7\", \"h3_6\",\n",
        "    # Species identification\n",
        "    \"speciesKey\", \"taxonKey\", \"species\", \"scientificName\",\n",
        "    # Dataset\n",
        "    \"datasetKey\",\n",
        "    # Coordinate quality\n",
        "    \"coordinateUncertaintyInMeters\",\n",
        "    # IUCN\n",
        "    \"iucn_cat\", \"iucnRedListCategory\",\n",
        "    # Invasive flags (for future DQI extension)\n",
        "    \"is_invasive_any\",\n",
        "    # Partition keys (may already be present as columns)\n",
        "    \"country\", \"year\",\n",
        "]\n",
        "\n",
        "\n",
        "def read_input(country: str, year: int) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Read one silver partition from S3 with column projection.\n",
        "\n",
        "    Uses pyarrow's native C++ S3FileSystem (fs_read) which pre-fetches\n",
        "    row-groups in parallel – significantly faster than s3fs for large files.\n",
        "    Only columns relevant to metric computation are loaded.\n",
        "    \"\"\"\n",
        "    # Native pyarrow paths don't have an \"s3://\" prefix\n",
        "    native_path = f\"{S3_BUCKET}/{SILVER_PREFIX}/country={country}/year={year}\"\n",
        "    log_path    = f\"s3://{native_path}\"\n",
        "\n",
        "    # Existence check via pyarrow native (avoids s3fs recursive listing)\n",
        "    info = fs_read.get_file_info(native_path)\n",
        "    if info.type == pafs.FileType.NotFound:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Silver partition not found: {log_path}. \"\n",
        "            \"Run gbif_bronze_to_silver.ipynb first.\"\n",
        "        )\n",
        "\n",
        "    log.info(\"Reading silver: %s\", log_path)\n",
        "    t0 = time.time()\n",
        "\n",
        "    dataset = ds.dataset(native_path, filesystem=fs_read, format=\"parquet\")\n",
        "\n",
        "    # Intersect desired columns with what actually exists in the schema\n",
        "    available = set(dataset.schema.names)\n",
        "    avail_lower = {c.lower().replace(\"_\", \"\"): c for c in available}\n",
        "    project = []\n",
        "    for want in _CANDIDATE_COLS:\n",
        "        key = want.lower().replace(\"_\", \"\")\n",
        "        if key in avail_lower:\n",
        "            project.append(avail_lower[key])\n",
        "\n",
        "    log.info(\"Projecting %d / %d columns – starting download…\", len(project), len(available))\n",
        "\n",
        "    # use_threads=True lets pyarrow read columns in parallel across row-groups\n",
        "    table = dataset.scanner(columns=project, use_threads=True).to_table()\n",
        "    df = table.to_pandas()\n",
        "\n",
        "    elapsed = time.time() - t0\n",
        "    log.info(\n",
        "        \"Loaded %d rows, %d columns in %.1fs (%.0f MB RAM)\",\n",
        "        len(df), len(df.columns), elapsed,\n",
        "        df.memory_usage(deep=True).sum() / 1e6,\n",
        "    )\n",
        "\n",
        "    # Ensure partition key columns exist\n",
        "    if \"country\" not in df.columns:\n",
        "        df[\"country\"] = country\n",
        "    if \"year\" not in df.columns:\n",
        "        df[\"year\"] = int(year)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# 2. COMPUTE METRICS PER H3 RESOLUTION\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def _diversity_vectorized(sp_counts: pd.Series) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute Shannon-Wiener H and Simpson 1-D **without any Python-level loops**.\n",
        "\n",
        "    sp_counts: Series indexed by (h3_cell, species_id) with observation counts.\n",
        "\n",
        "    Strategy (fully vectorized):\n",
        "      1. total_per_cell = groupby(h3).sum()  → broadcast via transform\n",
        "      2. p_i = count / total  (element-wise)\n",
        "      3. shannon_H = -Σ p_i * log(p_i)  per cell  (groupby.sum on the product)\n",
        "      4. simpson   = 1 - Σ p_i²          per cell  (groupby.sum on p²)\n",
        "\n",
        "    Eliminates the O(n_cells) Python-function-call overhead of groupby.apply().\n",
        "    \"\"\"\n",
        "    h3_level = sp_counts.index.names[0]\n",
        "\n",
        "    # Proportions: broadcast total back to each (cell, species) row\n",
        "    total = sp_counts.groupby(level=h3_level).transform(\"sum\")\n",
        "    p = sp_counts / total                           # p_i for every (cell, species)\n",
        "\n",
        "    # Shannon: -Σ p·log(p)  – clip to avoid log(0), zeros contribute 0\n",
        "    log_p = np.log(p.clip(lower=1e-300))\n",
        "    shannon = -(p * log_p).groupby(level=h3_level).sum().rename(\"shannon_H\")\n",
        "\n",
        "    # Simpson: 1 - Σ p²\n",
        "    simpson = (1.0 - (p ** 2).groupby(level=h3_level).sum()).rename(\"simpson_1_minus_D\")\n",
        "\n",
        "    return pd.concat([shannon, simpson], axis=1).reset_index()\n",
        "\n",
        "\n",
        "def compute_metrics(\n",
        "    df: pd.DataFrame,\n",
        "    country: str,\n",
        "    year: int,\n",
        "    h3_resolution: int,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Aggregate all metrics for one (country, year, h3_resolution).\n",
        "\n",
        "    Returns a DataFrame with one row per H3 cell and all metric columns.\n",
        "    \"\"\"\n",
        "    h3_col    = f\"h3_{h3_resolution}\"\n",
        "    sk_col    = _resolve_species_col(df)\n",
        "    ds_col    = _find_col(df, \"datasetKey\")\n",
        "    unc_col   = _find_col(df, \"coordinateUncertaintyInMeters\")\n",
        "    iucn_col  = _resolve_iucn_col(df)\n",
        "\n",
        "    if h3_col not in df.columns:\n",
        "        raise ValueError(f\"Column {h3_col!r} not found. Available: {list(df.columns)}\")\n",
        "\n",
        "    log.info(\n",
        "        \"  res=%d | rows=%d | sk=%s | unc=%s | iucn=%s\",\n",
        "        h3_resolution, len(df), sk_col, unc_col, iucn_col,\n",
        "    )\n",
        "\n",
        "    # ── 2a. Base counts ───────────────────────────────────────────────────────\n",
        "    g = df.groupby(h3_col)\n",
        "    agg = g.size().rename(\"observation_count\").reset_index()\n",
        "\n",
        "    # ── 2b. Species richness ─────────────────────────────────────────────────\n",
        "    if sk_col:\n",
        "        sr = g[sk_col].nunique().rename(\"species_richness_cell\")\n",
        "        agg = agg.merge(sr.reset_index(), on=h3_col, how=\"left\")\n",
        "    else:\n",
        "        agg[\"species_richness_cell\"] = pd.NA\n",
        "\n",
        "    # ── 2c. Unique datasets ───────────────────────────────────────────────────\n",
        "    if ds_col:\n",
        "        ud = g[ds_col].nunique().rename(\"unique_datasets\")\n",
        "        agg = agg.merge(ud.reset_index(), on=h3_col, how=\"left\")\n",
        "    else:\n",
        "        agg[\"unique_datasets\"] = pd.NA\n",
        "\n",
        "    # ── 2d. Coordinate uncertainty ────────────────────────────────────────────\n",
        "    if unc_col:\n",
        "        unc = pd.to_numeric(df[unc_col], errors=\"coerce\")\n",
        "        tmp = df.assign(_unc=unc)\n",
        "        avg_unc = tmp.groupby(h3_col)[\"_unc\"].mean().rename(\"avg_coordinate_uncertainty_m\")\n",
        "        pct_gt  = (\n",
        "            tmp.assign(_gt10k=(unc > 10_000).astype(float))\n",
        "               .groupby(h3_col)[\"_gt10k\"].mean()\n",
        "               .rename(\"pct_uncertainty_gt_10km\")\n",
        "        )\n",
        "        agg = agg.merge(avg_unc.reset_index(), on=h3_col, how=\"left\")\n",
        "        agg = agg.merge(pct_gt.reset_index(),  on=h3_col, how=\"left\")\n",
        "    else:\n",
        "        agg[\"avg_coordinate_uncertainty_m\"] = pd.NA\n",
        "        agg[\"pct_uncertainty_gt_10km\"] = pd.NA\n",
        "\n",
        "    # ── 2e. IUCN / Threat metrics ─────────────────────────────────────────────\n",
        "    if iucn_col and sk_col:\n",
        "        df_iucn = df.loc[\n",
        "            df[iucn_col].notna() & (df[iucn_col].astype(str).str.strip() != \"\")\n",
        "        ].copy()\n",
        "\n",
        "        # n_assessed_species\n",
        "        n_assessed = (\n",
        "            df_iucn.groupby(h3_col)[sk_col].nunique().rename(\"n_assessed_species\")\n",
        "        )\n",
        "        agg = agg.merge(n_assessed.reset_index(), on=h3_col, how=\"left\")\n",
        "\n",
        "        # n_sp_{cat} – only emit column when ≥1 species has that category\n",
        "        present_cats = [\n",
        "            c for c in IUCN_ALL_CATS if (df_iucn[iucn_col] == c).any()\n",
        "        ]\n",
        "        for cat in present_cats:\n",
        "            col_name = f\"n_sp_{cat.lower()}\"\n",
        "            cnt = (\n",
        "                df_iucn[df_iucn[iucn_col] == cat]\n",
        "                .groupby(h3_col)[sk_col].nunique()\n",
        "                .rename(col_name)\n",
        "            )\n",
        "            agg = agg.merge(cnt.reset_index(), on=h3_col, how=\"left\")\n",
        "\n",
        "        # n_threatened_species (CR + EN + VU)\n",
        "        df_thr = df_iucn[df_iucn[iucn_col].isin([\"CR\", \"EN\", \"VU\"])]\n",
        "        n_thr = (\n",
        "            df_thr.groupby(h3_col)[sk_col].nunique().rename(\"n_threatened_species\")\n",
        "        )\n",
        "        agg = agg.merge(n_thr.reset_index(), on=h3_col, how=\"left\")\n",
        "\n",
        "        # threat_score_weighted – over DISTINCT (cell, species)\n",
        "        # Vectorized: map each iucn value to a severity int, take max per\n",
        "        # (cell, species), map back to weight, sum per cell.  No Python apply().\n",
        "        _SEV_MAP = {\"CR\": 5, \"EN\": 4, \"VU\": 3, \"NT\": 2, \"LC\": 1, \"DD\": 0, \"NE\": 0}\n",
        "        _SEV_TO_WEIGHT = {5: IUCN_WEIGHTS.get(\"CR\", 0), 4: IUCN_WEIGHTS.get(\"EN\", 0),\n",
        "                          3: IUCN_WEIGHTS.get(\"VU\", 0), 2: IUCN_WEIGHTS.get(\"NT\", 0),\n",
        "                          1: 0, 0: 0}\n",
        "        sev = df_iucn[iucn_col].map(_SEV_MAP).fillna(-1).astype(np.int8)\n",
        "        # max severity per (cell, species) → one row per distinct species per cell\n",
        "        sp_max_sev = (\n",
        "            df_iucn.assign(_sev=sev)\n",
        "            .groupby([h3_col, sk_col])[\"_sev\"].max()\n",
        "        )\n",
        "        weight = sp_max_sev.map(_SEV_TO_WEIGHT).fillna(0)\n",
        "        threat_score = weight.groupby(level=h3_col).sum().rename(\"threat_score_weighted\")\n",
        "        agg = agg.merge(threat_score.reset_index(), on=h3_col, how=\"left\")\n",
        "\n",
        "    else:\n",
        "        for col in [\"n_assessed_species\", \"n_threatened_species\", \"threat_score_weighted\"]:\n",
        "            agg[col] = pd.NA\n",
        "\n",
        "    # ── 2f. Diversity metrics (fully vectorized, no groupby.apply) ───────────\n",
        "    if sk_col:\n",
        "        # Species counts per (h3_cell, species) – re-used for both diversity\n",
        "        # and species-richness (avoids a second full scan).\n",
        "        sp_counts = df.groupby([h3_col, sk_col]).size().rename(\"_n\")\n",
        "        div = _diversity_vectorized(sp_counts)\n",
        "        agg = agg.merge(div, on=h3_col, how=\"left\")\n",
        "    else:\n",
        "        agg[\"shannon_H\"] = pd.NA\n",
        "        agg[\"simpson_1_minus_D\"] = pd.NA\n",
        "\n",
        "    # ── 2g. Data Quality Index (0–1) ──────────────────────────────────────────\n",
        "    #\n",
        "    # Components (each in [0, 1]):\n",
        "    #   c1 – species-id completeness: pct of records with a valid species ID\n",
        "    #   c2 – uncertainty quality: (1 - pct_uncertainty_gt_10km)  [if available]\n",
        "    #   c3 – iucn coverage: (1 - pct_iucn_missing)             [if iucn column exists]\n",
        "    #\n",
        "    # DQI = mean of available components\n",
        "    # Coordinate completeness is already 1.0 after silver cleaning (all rows have coords).\n",
        "\n",
        "    dqi_parts: list[pd.Series] = []\n",
        "\n",
        "    if sk_col:\n",
        "        c1 = (\n",
        "            df.assign(_has_sp=df[sk_col].notna().astype(float))\n",
        "              .groupby(h3_col)[\"_has_sp\"].mean()\n",
        "              .rename(\"_c1\")\n",
        "        )\n",
        "        dqi_parts.append(c1)\n",
        "\n",
        "    if \"pct_uncertainty_gt_10km\" in agg.columns:\n",
        "        c2 = (1.0 - agg.set_index(h3_col)[\"pct_uncertainty_gt_10km\"].fillna(0)).rename(\"_c2\")\n",
        "        dqi_parts.append(c2)\n",
        "\n",
        "    if iucn_col:\n",
        "        c3 = (\n",
        "            df.assign(_iucn_missing=df[iucn_col].isna().astype(float))\n",
        "              .groupby(h3_col)[\"_iucn_missing\"].mean()\n",
        "              .rsub(1)\n",
        "              .rename(\"_c3\")\n",
        "        )\n",
        "        dqi_parts.append(c3)\n",
        "\n",
        "    if dqi_parts:\n",
        "        dqi_df = pd.concat(dqi_parts, axis=1).reset_index()\n",
        "        dqi_df[\"dqi\"] = dqi_df.iloc[:, 1:].mean(axis=1)\n",
        "        agg = agg.merge(dqi_df[[h3_col, \"dqi\"]], on=h3_col, how=\"left\")\n",
        "    else:\n",
        "        agg[\"dqi\"] = pd.NA\n",
        "\n",
        "    # ── 2h. Partition metadata ────────────────────────────────────────────────\n",
        "    agg.rename(columns={h3_col: \"h3_index\"}, inplace=True)\n",
        "    agg[\"h3_resolution\"] = h3_resolution\n",
        "    agg[\"country\"]       = country\n",
        "    agg[\"year\"]          = int(year)\n",
        "\n",
        "    # Normalise int columns (nunique returns int64, NaN forces float64 after merge)\n",
        "    int_cols = [\n",
        "        \"observation_count\", \"species_richness_cell\", \"unique_datasets\",\n",
        "        \"n_assessed_species\", \"n_threatened_species\",\n",
        "    ] + [f\"n_sp_{c.lower()}\" for c in IUCN_ALL_CATS if f\"n_sp_{c.lower()}\" in agg.columns]\n",
        "    for col in int_cols:\n",
        "        if col in agg.columns:\n",
        "            agg[col] = agg[col].astype(\"Int64\")  # nullable integer\n",
        "\n",
        "    return agg\n",
        "\n",
        "\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# 3. WRITE GOLD\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def write_gold(agg: pd.DataFrame, country: str, year: int, h3_resolution: int) -> str:\n",
        "    \"\"\"\n",
        "    Write metrics for one (country, year, h3_resolution) slice to the gold layer.\n",
        "\n",
        "    Path: s3://{S3_BUCKET}/{GOLD_PREFIX}/country={country}/year={year}/h3_resolution={h3_resolution}/\n",
        "    \"\"\"\n",
        "    s3_root = (\n",
        "        f\"{S3_BUCKET}/{GOLD_PREFIX}\"\n",
        "        f\"/country={country}/year={year}/h3_resolution={h3_resolution}\"\n",
        "    )\n",
        "    log.info(\"Writing %d cells to s3://%s …\", len(agg), s3_root)\n",
        "\n",
        "    table = pa.Table.from_pandas(agg, preserve_index=False)\n",
        "    pq.write_to_dataset(\n",
        "        table,\n",
        "        root_path=f\"s3://{s3_root}\",\n",
        "        filesystem=fs,\n",
        "        existing_data_behavior=\"delete_matching\",\n",
        "        row_group_size=PARQUET_ROW_GROUP_SIZE,\n",
        "        compression=PARQUET_COMPRESSION,\n",
        "        write_statistics=True,\n",
        "    )\n",
        "    s3_uri = f\"s3://{s3_root}\"\n",
        "    log.info(\"Written: %s\", s3_uri)\n",
        "    return s3_uri\n",
        "\n",
        "\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "# MAIN PIPELINE\n",
        "# ══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "years = list(range(YEAR_END, YEAR_START - 1, -1))  # newest first\n",
        "partition_plan = [(c, y) for c in COUNTRIES for y in years]\n",
        "\n",
        "log.info(\n",
        "    \"Gold pipeline: %d (country×year) partitions × %d resolutions = %d total writes\",\n",
        "    len(partition_plan), len(H3_RESOLUTIONS), len(partition_plan) * len(H3_RESOLUTIONS),\n",
        ")\n",
        "\n",
        "completed: list[dict] = []\n",
        "errors:    list[dict] = []\n",
        "\n",
        "for country, year in partition_plan:\n",
        "    log.info(\"\\n── %s / %s ──────────────────────────────────────────────────\", country, year)\n",
        "    t_read = time.time()\n",
        "\n",
        "    try:\n",
        "        df = read_input(country, year)\n",
        "    except FileNotFoundError as exc:\n",
        "        log.error(\"%s\", exc)\n",
        "        errors.append({\"country\": country, \"year\": year, \"h3_resolution\": \"all\", \"error\": str(exc)})\n",
        "        continue\n",
        "\n",
        "    log.info(\"Read done in %.1fs\", time.time() - t_read)\n",
        "\n",
        "    for res in H3_RESOLUTIONS:\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            agg     = compute_metrics(df, country, year, res)\n",
        "            s3_uri  = write_gold(agg, country, year, res)\n",
        "            elapsed = time.time() - t0\n",
        "\n",
        "            completed.append({\n",
        "                \"country\":      country,\n",
        "                \"year\":         year,\n",
        "                \"h3_resolution\": res,\n",
        "                \"n_cells\":      len(agg),\n",
        "                \"s3_uri\":       s3_uri,\n",
        "                \"elapsed_s\":    round(elapsed, 1),\n",
        "            })\n",
        "            log.info(\"✓ res=%d | %d cells | %.1fs\", res, len(agg), elapsed)\n",
        "\n",
        "        except Exception as exc:\n",
        "            log.error(\"✗ %s/%s res=%d: %s\", country, year, res, exc, exc_info=True)\n",
        "            errors.append({\"country\": country, \"year\": year, \"h3_resolution\": res, \"error\": str(exc)})\n",
        "\n",
        "\n",
        "# ── Summary ───────────────────────────────────────────────────────────────────\n",
        "print()\n",
        "print(\"═\" * 60)\n",
        "print(f\"Gold pipeline complete: {len(completed)} succeeded, {len(errors)} failed\")\n",
        "print(\"═\" * 60)\n",
        "\n",
        "if completed:\n",
        "    print(\"\\nCompleted:\")\n",
        "    display(pd.DataFrame(completed))\n",
        "\n",
        "if errors:\n",
        "    print(\"\\nFailed:\")\n",
        "    display(pd.DataFrame(errors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading: s3://ie-datalake/gold/gbif_cell_metrics/country=ES/year=2024/h3_resolution=8\n",
            "\n",
            "Shape: 149,508 cells × 18 columns\n",
            "Columns: ['h3_index', 'observation_count', 'species_richness_cell', 'unique_datasets', 'avg_coordinate_uncertainty_m', 'pct_uncertainty_gt_10km', 'n_assessed_species', 'n_sp_cr', 'n_sp_en', 'n_sp_vu', 'n_threatened_species', 'threat_score_weighted', 'shannon_H', 'simpson_1_minus_D', 'dqi', 'h3_resolution', 'country', 'year']\n",
            "\n",
            "Top 10 cells by species richness:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>h3_index</th>\n",
              "      <th>observation_count</th>\n",
              "      <th>species_richness_cell</th>\n",
              "      <th>shannon_H</th>\n",
              "      <th>simpson_1_minus_D</th>\n",
              "      <th>n_threatened_species</th>\n",
              "      <th>threat_score_weighted</th>\n",
              "      <th>dqi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8839560545fffff</td>\n",
              "      <td>1516</td>\n",
              "      <td>611</td>\n",
              "      <td>6.105660</td>\n",
              "      <td>0.996958</td>\n",
              "      <td>3</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.661390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>88184b7687fffff</td>\n",
              "      <td>13959</td>\n",
              "      <td>570</td>\n",
              "      <td>4.947319</td>\n",
              "      <td>0.988813</td>\n",
              "      <td>4</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.671896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>88392d00e9fffff</td>\n",
              "      <td>3282</td>\n",
              "      <td>548</td>\n",
              "      <td>5.688569</td>\n",
              "      <td>0.994793</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.665651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>883919d9a3fffff</td>\n",
              "      <td>2132</td>\n",
              "      <td>543</td>\n",
              "      <td>5.637586</td>\n",
              "      <td>0.993599</td>\n",
              "      <td>2</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.663852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>88394460d7fffff</td>\n",
              "      <td>8069</td>\n",
              "      <td>465</td>\n",
              "      <td>4.855625</td>\n",
              "      <td>0.985303</td>\n",
              "      <td>5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.653654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>883945c751fffff</td>\n",
              "      <td>1638</td>\n",
              "      <td>458</td>\n",
              "      <td>5.458804</td>\n",
              "      <td>0.992440</td>\n",
              "      <td>2</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.666463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8839440b1bfffff</td>\n",
              "      <td>1126</td>\n",
              "      <td>444</td>\n",
              "      <td>5.723554</td>\n",
              "      <td>0.995054</td>\n",
              "      <td>2</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.663114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8839444699fffff</td>\n",
              "      <td>1260</td>\n",
              "      <td>428</td>\n",
              "      <td>5.474435</td>\n",
              "      <td>0.990690</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>883971a053fffff</td>\n",
              "      <td>1718</td>\n",
              "      <td>426</td>\n",
              "      <td>5.425145</td>\n",
              "      <td>0.992412</td>\n",
              "      <td>3</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.666279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8839442a01fffff</td>\n",
              "      <td>672</td>\n",
              "      <td>425</td>\n",
              "      <td>5.904638</td>\n",
              "      <td>0.996774</td>\n",
              "      <td>4</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.662698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          h3_index  observation_count  species_richness_cell  shannon_H  \\\n",
              "0  8839560545fffff               1516                    611   6.105660   \n",
              "1  88184b7687fffff              13959                    570   4.947319   \n",
              "2  88392d00e9fffff               3282                    548   5.688569   \n",
              "3  883919d9a3fffff               2132                    543   5.637586   \n",
              "4  88394460d7fffff               8069                    465   4.855625   \n",
              "5  883945c751fffff               1638                    458   5.458804   \n",
              "6  8839440b1bfffff               1126                    444   5.723554   \n",
              "7  8839444699fffff               1260                    428   5.474435   \n",
              "8  883971a053fffff               1718                    426   5.425145   \n",
              "9  8839442a01fffff                672                    425   5.904638   \n",
              "\n",
              "   simpson_1_minus_D  n_threatened_species  threat_score_weighted       dqi  \n",
              "0           0.996958                     3                    9.0  0.661390  \n",
              "1           0.988813                     4                   13.0  0.671896  \n",
              "2           0.994793                     5                   18.0  0.665651  \n",
              "3           0.993599                     2                    7.0  0.663852  \n",
              "4           0.985303                     5                   16.0  0.653654  \n",
              "5           0.992440                     2                    9.0  0.666463  \n",
              "6           0.995054                     2                    7.0  0.663114  \n",
              "7           0.990690                     1                    4.0  0.666667  \n",
              "8           0.992412                     3                   10.0  0.666279  \n",
              "9           0.996774                     4                   17.0  0.662698  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Metric summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>observation_count</th>\n",
              "      <th>species_richness_cell</th>\n",
              "      <th>shannon_H</th>\n",
              "      <th>simpson_1_minus_D</th>\n",
              "      <th>dqi</th>\n",
              "      <th>n_threatened_species</th>\n",
              "      <th>threat_score_weighted</th>\n",
              "      <th>avg_coordinate_uncertainty_m</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>149508.0</td>\n",
              "      <td>149508.0</td>\n",
              "      <td>148806.000000</td>\n",
              "      <td>148806.000000</td>\n",
              "      <td>149508.000000</td>\n",
              "      <td>29088.0</td>\n",
              "      <td>29088.000000</td>\n",
              "      <td>1.055280e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>49.63826</td>\n",
              "      <td>12.054405</td>\n",
              "      <td>1.354522</td>\n",
              "      <td>0.505073</td>\n",
              "      <td>0.631973</td>\n",
              "      <td>1.361971</td>\n",
              "      <td>4.658622</td>\n",
              "      <td>7.370860e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>417.825464</td>\n",
              "      <td>22.323385</td>\n",
              "      <td>1.354814</td>\n",
              "      <td>0.408933</td>\n",
              "      <td>0.114038</td>\n",
              "      <td>0.853279</td>\n",
              "      <td>2.869122</td>\n",
              "      <td>3.696441e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.100000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.100000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.507026</td>\n",
              "      <td>0.914601</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.340982e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>49094.0</td>\n",
              "      <td>611.0</td>\n",
              "      <td>6.105660</td>\n",
              "      <td>0.996958</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>2.499735e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       observation_count  species_richness_cell      shannon_H  \\\n",
              "count           149508.0               149508.0  148806.000000   \n",
              "mean            49.63826              12.054405       1.354522   \n",
              "std           417.825464              22.323385       1.354814   \n",
              "min                  1.0                    0.0      -0.000000   \n",
              "25%                  1.0                    1.0       0.000000   \n",
              "50%                  3.0                    3.0       1.098612   \n",
              "75%                 16.0                   13.0       2.507026   \n",
              "max              49094.0                  611.0       6.105660   \n",
              "\n",
              "       simpson_1_minus_D            dqi  n_threatened_species  \\\n",
              "count      148806.000000  149508.000000               29088.0   \n",
              "mean            0.505073       0.631973              1.361971   \n",
              "std             0.408933       0.114038              0.853279   \n",
              "min             0.000000       0.000000                   1.0   \n",
              "25%             0.000000       0.666667                   1.0   \n",
              "50%             0.666667       0.666667                   1.0   \n",
              "75%             0.914601       0.666667                   1.0   \n",
              "max             0.996958       1.000000                  11.0   \n",
              "\n",
              "       threat_score_weighted  avg_coordinate_uncertainty_m  \n",
              "count           29088.000000                  1.055280e+05  \n",
              "mean                4.658622                  7.370860e+03  \n",
              "std                 2.869122                  3.696441e+04  \n",
              "min                 3.000000                  7.100000e-01  \n",
              "25%                 3.000000                  8.000000e+00  \n",
              "50%                 4.000000                  6.100000e+01  \n",
              "75%                 5.000000                  4.340982e+03  \n",
              "max                41.000000                  2.499735e+06  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# VERIFY – read back one slice and inspect the schema + sample rows\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "VERIFY_COUNTRY    = COUNTRIES[0]\n",
        "VERIFY_YEAR       = YEAR_END\n",
        "VERIFY_RESOLUTION = 8  # medium resolution for a readable preview\n",
        "\n",
        "s3_path = (\n",
        "    f\"{S3_BUCKET}/{GOLD_PREFIX}\"\n",
        "    f\"/country={VERIFY_COUNTRY}/year={VERIFY_YEAR}\"\n",
        "    f\"/h3_resolution={VERIFY_RESOLUTION}\"\n",
        ")\n",
        "print(f\"Reading: s3://{s3_path}\")\n",
        "\n",
        "sample = ds.dataset(s3_path, filesystem=fs_read, format=\"parquet\").to_table().to_pandas()\n",
        "\n",
        "print(f\"\\nShape: {sample.shape[0]:,} cells × {sample.shape[1]} columns\")\n",
        "print(f\"Columns: {list(sample.columns)}\")\n",
        "\n",
        "print(\"\\nTop 10 cells by species richness:\")\n",
        "display(\n",
        "    sample.sort_values(\"species_richness_cell\", ascending=False)\n",
        "          [[\"h3_index\", \"observation_count\", \"species_richness_cell\",\n",
        "            \"shannon_H\", \"simpson_1_minus_D\",\n",
        "            \"n_threatened_species\", \"threat_score_weighted\", \"dqi\"]]\n",
        "          .head(10)\n",
        "          .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(\"\\nMetric summary:\")\n",
        "display(\n",
        "    sample[[\n",
        "        \"observation_count\", \"species_richness_cell\",\n",
        "        \"shannon_H\", \"simpson_1_minus_D\", \"dqi\",\n",
        "        \"n_threatened_species\", \"threat_score_weighted\",\n",
        "        \"avg_coordinate_uncertainty_m\",\n",
        "    ]].describe()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>h3_index</th>\n",
              "      <th>observation_count</th>\n",
              "      <th>species_richness_cell</th>\n",
              "      <th>unique_datasets</th>\n",
              "      <th>avg_coordinate_uncertainty_m</th>\n",
              "      <th>pct_uncertainty_gt_10km</th>\n",
              "      <th>n_assessed_species</th>\n",
              "      <th>n_sp_cr</th>\n",
              "      <th>n_sp_en</th>\n",
              "      <th>n_sp_vu</th>\n",
              "      <th>n_threatened_species</th>\n",
              "      <th>threat_score_weighted</th>\n",
              "      <th>shannon_H</th>\n",
              "      <th>simpson_1_minus_D</th>\n",
              "      <th>dqi</th>\n",
              "      <th>h3_resolution</th>\n",
              "      <th>country</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8818004109fffff</td>\n",
              "      <td>141</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.315729</td>\n",
              "      <td>0.889895</td>\n",
              "      <td>0.671395</td>\n",
              "      <td>8</td>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>88180055a1fffff</td>\n",
              "      <td>215</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.428779</td>\n",
              "      <td>0.889995</td>\n",
              "      <td>0.691473</td>\n",
              "      <td>8</td>\n",
              "      <td>ES</td>\n",
              "      <td>2024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          h3_index  observation_count  species_richness_cell  unique_datasets  \\\n",
              "0  8818004109fffff                141                     13                1   \n",
              "1  88180055a1fffff                215                     18                1   \n",
              "\n",
              "   avg_coordinate_uncertainty_m  pct_uncertainty_gt_10km  n_assessed_species  \\\n",
              "0                           NaN                      0.0                   1   \n",
              "1                           NaN                      0.0                   4   \n",
              "\n",
              "   n_sp_cr  n_sp_en  n_sp_vu  n_threatened_species  threat_score_weighted  \\\n",
              "0     <NA>     <NA>        1                     1                    3.0   \n",
              "1     <NA>        1        3                     4                   13.0   \n",
              "\n",
              "   shannon_H  simpson_1_minus_D       dqi  h3_resolution country  year  \n",
              "0   2.315729           0.889895  0.671395              8      ES  2024  \n",
              "1   2.428779           0.889995  0.691473              8      ES  2024  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample.head(2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

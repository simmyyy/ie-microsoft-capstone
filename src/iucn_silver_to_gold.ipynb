{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IUCN Silver → Gold: species profiles\n",
        "\n",
        "Reads `species_profiles.json` from the **silver** layer, converts to Parquet and writes to **gold**.\n",
        "\n",
        "| Layer | S3 path |\n",
        "|-------|---------|\n",
        "| Silver in  | `s3://ie-datalake/silver/iucn_species_profiles/country=XX/year=YYYY/species_profiles.json` |\n",
        "| Gold out   | `s3://ie-datalake/gold/iucn_species_profiles/country=XX/year=YYYY/` |\n",
        "\n",
        "Partition structure: `country` + `year` (same as silver)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q pyarrow s3fs pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import s3fs\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\", datefmt=\"%H:%M:%S\")\n",
        "log = logging.getLogger(__name__)\n",
        "\n",
        "# ─── Config ─────────────────────────────────────────────────────────────────\n",
        "S3_BUCKET       = \"ie-datalake\"\n",
        "SILVER_PREFIX   = \"silver/iucn_species_profiles\"\n",
        "GOLD_PREFIX     = \"gold/iucn_species_profiles\"\n",
        "AWS_PROFILE     = \"486717354268_PowerUserAccess\"\n",
        "\n",
        "COUNTRIES = None   # None = all\n",
        "YEARS     = None   # None = all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "21:42:35 [INFO] Found credentials in shared credentials file: ~/.aws/credentials\n",
            "21:42:35 [INFO] S3 ready (profile=486717354268_PowerUserAccess)\n"
          ]
        }
      ],
      "source": [
        "# ─── S3 connection ─────────────────────────────────────────────────────────\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.config import Config\n",
        "\n",
        "session = boto3.Session(profile_name=AWS_PROFILE)\n",
        "creds   = session.get_credentials()\n",
        "\n",
        "fs = s3fs.S3FileSystem(\n",
        "    key=creds.access_key,\n",
        "    secret=creds.secret_key,\n",
        "    token=creds.token,\n",
        "    client_kwargs={\"region_name\": session.region_name or \"eu-west-2\"},\n",
        ")\n",
        "\n",
        "log.info(\"S3 ready (profile=%s)\", AWS_PROFILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "21:42:38 [INFO] Found 1 partition(s)\n",
            "21:42:38 [INFO]   country=ES year=2024\n"
          ]
        }
      ],
      "source": [
        "# ─── Discover silver partitions ─────────────────────────────────────────────\n",
        "def list_partitions() -> list[dict]:\n",
        "    \"\"\"List (country, year) partitions that have species_profiles.json.\"\"\"\n",
        "    base = f\"{S3_BUCKET}/{SILVER_PREFIX}\"\n",
        "    parts = []\n",
        "    try:\n",
        "        country_dirs = fs.ls(base, detail=False)\n",
        "    except FileNotFoundError:\n",
        "        log.warning(\"No silver partitions found at %s\", base)\n",
        "        return []\n",
        "\n",
        "    for country_dir in country_dirs:\n",
        "        country = country_dir.split(\"country=\")[-1].rstrip(\"/\")\n",
        "        if COUNTRIES and country not in COUNTRIES:\n",
        "            continue\n",
        "        try:\n",
        "            year_dirs = fs.ls(country_dir, detail=False)\n",
        "        except Exception:\n",
        "            continue\n",
        "        for year_dir in year_dirs:\n",
        "            try:\n",
        "                year = int(year_dir.split(\"year=\")[-1].rstrip(\"/\"))\n",
        "            except ValueError:\n",
        "                continue\n",
        "            if YEARS and year not in YEARS:\n",
        "                continue\n",
        "            json_path = f\"{year_dir}/species_profiles.json\"\n",
        "            if fs.exists(json_path):\n",
        "                parts.append({\"country\": country, \"year\": year, \"json_path\": json_path})\n",
        "\n",
        "    return parts\n",
        "\n",
        "partitions = list_partitions()\n",
        "log.info(\"Found %d partition(s)\", len(partitions))\n",
        "for p in partitions:\n",
        "    log.info(\"  country=%s year=%s\", p[\"country\"], p[\"year\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "21:42:44 [INFO] ── ES / 2024 ─────────────────────────────────────\n",
            "21:42:45 [INFO]   Written 337 rows → s3://ie-datalake/gold/iucn_species_profiles/country=ES/year=2024/\n",
            "21:42:45 [INFO] Done.\n"
          ]
        }
      ],
      "source": [
        "# ─── Process each partition: JSON → Parquet → Gold ─────────────────────────\n",
        "LIST_COLS = [\"common_names\", \"threats\", \"conservation_actions\",\n",
        "             \"systems\", \"biogeographical_realms\", \"habitats\"]\n",
        "\n",
        "for part in partitions:\n",
        "    country, year = part[\"country\"], part[\"year\"]\n",
        "    log.info(\"── %s / %s ─────────────────────────────────────\", country, year)\n",
        "\n",
        "    # 1. Read JSON from silver\n",
        "    with fs.open(part[\"json_path\"], \"r\") as f:\n",
        "        profiles = json.load(f)\n",
        "\n",
        "    if not profiles:\n",
        "        log.warning(\"  Empty JSON, skipping\")\n",
        "        continue\n",
        "\n",
        "    # 2. To DataFrame, serialize list columns for Parquet\n",
        "    df = pd.DataFrame(profiles)\n",
        "    for col in LIST_COLS:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(\n",
        "                lambda v: json.dumps(v, ensure_ascii=False) if isinstance(v, list) else v\n",
        "            )\n",
        "\n",
        "    # 3. Add partition columns\n",
        "    df[\"country\"] = country\n",
        "    df[\"year\"]    = year\n",
        "\n",
        "    # 4. Write to gold\n",
        "    s3_base = f\"{S3_BUCKET}/{GOLD_PREFIX}/country={country}/year={year}\"\n",
        "    table = pa.Table.from_pandas(df, preserve_index=False)\n",
        "    pq.write_to_dataset(\n",
        "        table,\n",
        "        root_path=f\"s3://{s3_base}\",\n",
        "        filesystem=fs,\n",
        "        compression=\"snappy\",\n",
        "        existing_data_behavior=\"delete_matching\",\n",
        "    )\n",
        "\n",
        "    log.info(\"  Written %d rows → s3://%s/\", len(df), s3_base)\n",
        "\n",
        "log.info(\"Done.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
